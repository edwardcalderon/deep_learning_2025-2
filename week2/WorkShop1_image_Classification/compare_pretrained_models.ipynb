{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Pre-trained Models for Cat and Dog Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import (\n",
    "    EfficientNetB0, ResNet50, VGG16,\n",
    "    efficientnet, resnet, vgg16\n",
    ")\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "TRAIN_DIR = './dataset_dogs_vs_cats/train'\n",
    "TEST_DIR = './dataset_dogs_vs_cats/test'\n",
    "MODEL_SAVE_DIR = './saved_models'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EfficientNetB0 model\n",
    "base_effnet = EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_effnet.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = efficientnet.preprocess_input(inputs)\n",
    "x = base_effnet(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "effnet_model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "effnet_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "effnet_history = effnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(MODEL_SAVE_DIR, 'efficientnet_best.h5'),\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet50 model\n",
    "base_resnet = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_resnet.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = resnet.preprocess_input(inputs)\n",
    "x = base_resnet(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "resnet_model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "resnet_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "resnet_history = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(MODEL_SAVE_DIR, 'resnet50_best.h5'),\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VGG16 model\n",
    "base_vgg = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_vgg.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = vgg16.preprocess_input(inputs)\n",
    "x = base_vgg(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "vgg_model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "vgg_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(MODEL_SAVE_DIR, 'vgg16_best.h5'),\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "effnet_test_loss, effnet_test_acc = effnet_model.evaluate(test_generator)\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_generator)\n",
    "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_generator)\n",
    "\n",
    "print(f\"EfficientNetB0 Test Accuracy: {effnet_test_acc:.4f}\")\n",
    "print(f\"ResNet50 Test Accuracy: {resnet_test_acc:.4f}\")\n",
    "print(f\"VGG16 Test Accuracy: {vgg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} - Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} - Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot history for each model\n",
    "plot_history(effnet_history, 'EfficientNetB0')\n",
    "plot_history(resnet_history, 'ResNet50')\n",
    "plot_history(vgg_history, 'VGG16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing with Downloaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_downloaded_images(model, class_indices):\n",
    "    # Example image URLs\n",
    "    test_images = {\n",
    "        'cat1': 'https://cdn.pixabay.com/photo/2017/02/20/18/03/cat-2083492_1280.jpg',\n",
    "        'cat2': 'https://cdn.pixabay.com/photo/2014/11/30/14/11/cat-551554_1280.jpg',\n",
    "        'dog1': 'https://cdn.pixabay.com/photo/2016/12/13/05/15/puppy-1903313_1280.jpg',\n",
    "        'dog2': 'https://cdn.pixabay.com/photo/2018/01/09/11/04/dog-3071334_1280.jpg',\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, (name, url) in enumerate(test_images.items(), 1):\n",
    "        try:\n",
    "            # Download and preprocess image\n",
    "            response = requests.get(url)\n",
    "            img = Image.open(BytesIO(response.content)).resize(IMG_SIZE)\n",
    "            img_array = np.array(img) / 255.0\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = model.predict(img_array)[0][0]\n",
    "            predicted_class = 'dog' if prediction > 0.5 else 'cat'\n",
    "            confidence = prediction if predicted_class == 'dog' else (1 - prediction)\n",
    "            \n",
    "            # Plot image with prediction\n",
    "            plt.subplot(2, 2, i)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'Predicted: {predicted_class}\\nConfidence: {confidence:.2f}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {url}: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the best model\n",
    "# Determine the best model\n",
    "accuracies = {\n",
    "    'EfficientNetB0': effnet_test_acc,\n",
    "    'ResNet50': resnet_test_acc,\n",
    "    'VGG16': vgg_test_acc\n",
    "}\n",
    "\n",
    "best_model_name = max(accuracies, key=accuracies.get)\n",
    "best_model = {\n",
    "    'EfficientNetB0': effnet_model,\n",
    "    'ResNet50': resnet_model,\n",
    "    'VGG16': vgg_model\n",
    "}[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with test accuracy: {accuracies[best_model_name]:.4f}\")\n",
    "\n",
    "# Test with downloaded images\n",
    "print(\"\\nTesting with downloaded images...\")\n",
    "test_with_downloaded_images(best_model, test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save(os.path.join(MODEL_SAVE_DIR, 'best_model.h5'))\n",
    "print(f\"Best model saved to {os.path.join(MODEL_SAVE_DIR, 'best_model.h5')}\")\n",
    "print(\"You can now load this model using: model = tf.keras.models.load_model('saved_models/best_model.h5')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green', 'red'])\n",
    "plt.title('Model Comparison - Test Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations and Conclusions\n",
    "1. **Performance Comparison**:\n",
    "   - **EfficientNetB0**: {:.2f}% test accuracy\n",
    "   - **ResNet50**: {:.2f}% test accuracy\n",
    "   - **VGG16**: {:.2f}% test accuracy\n",
    "\n",
    "2. **Best Performing Model**:\n",
    "   - **{}** achieved the highest accuracy of {:.2f}% on the test set.\n",
    "\n",
    "3. **Training Observations**:\n",
    "   - [Add your observations about training stability, convergence speed, etc.]\n",
    "   - [Note any overfitting/underfitting issues]\n",
    "   - [Compare training times and computational requirements]\n",
    "\n",
    "4. **Recommendations**:\n",
    "   - [Suggest potential improvements or next steps]\n",
    "   - [Discuss limitations and future work]\n",
    "\n",
    "5. **Final Thoughts**:\n",
    "   [Add your overall conclusions and thoughts on the project]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
