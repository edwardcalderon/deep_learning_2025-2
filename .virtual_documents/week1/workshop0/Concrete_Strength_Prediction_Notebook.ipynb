





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de semilla para reproducibilidad
np.random.seed(42)

print("Librer√≠as importadas exitosamente")





# Cargar el dataset
print("Cargando dataset de concreto...")
data = pd.read_csv('Concrete_Data_Yeh.csv')

print(f"Dataset cargado: {data.shape[0]} muestras, {data.shape[1]} caracter√≠sticas")
print("\nCaracter√≠sticas del dataset:")
print(data.columns.tolist())

# Mostrar las primeras filas
print("\nPrimeras 5 filas del dataset:")
data.head()


# Estad√≠sticas descriptivas
print("Estad√≠sticas descriptivas:")
data.describe()


# Visualizaci√≥n de la distribuci√≥n de la variable objetivo
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(data['csMPa'], bins=30, alpha=0.7, edgecolor='black')
plt.xlabel('Resistencia a la Compresi√≥n (MPa)')
plt.ylabel('Frecuencia')
plt.title('Distribuci√≥n de la Resistencia del Concreto')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.boxplot(data['csMPa'])
plt.ylabel('Resistencia a la Compresi√≥n (MPa)')
plt.title('Diagrama de Caja de la Resistencia')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"Resistencia m√≠nima: {data['csMPa'].min():.2f} MPa")
print(f"Resistencia m√°xima: {data['csMPa'].max():.2f} MPa")
print(f"Resistencia promedio: {data['csMPa'].mean():.2f} MPa")





# Separar caracter√≠sticas y objetivo
X = data.drop("csMPa", axis=1).values
y = data["csMPa"].values
feature_names = data.columns[:-1].tolist()

print(f"Caracter√≠sticas (X): {X.shape}")
print(f"Variable objetivo (y): {y.shape}")
print(f"Nombres de caracter√≠sticas: {feature_names}")


# Dividir datos en entrenamiento, validaci√≥n y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

print(f"Conjunto de entrenamiento: {X_train.shape[0]} muestras")
print(f"Conjunto de validaci√≥n: {X_val.shape[0]} muestras")
print(f"Conjunto de prueba: {X_test.shape[0]} muestras")


# Normalizar caracter√≠sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

print("Datos normalizados exitosamente")
print(f"Media de caracter√≠sticas de entrenamiento: {X_train_scaled.mean(axis=0).round(3)}")
print(f"Desviaci√≥n est√°ndar de caracter√≠sticas de entrenamiento: {X_train_scaled.std(axis=0).round(3)}")





# Crear el modelo de red neuronal
print("Creando modelo de red neuronal...")

model = Sequential([
    Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')  # Salida de regresi√≥n
])

# Compilar el modelo
model.compile(optimizer=Adam(learning_rate=0.001), 
             loss='mse', 
             metrics=['mae'])

print("Arquitectura del modelo:")
model.summary()


# Entrenar el modelo
print("Entrenando modelo...")
history = model.fit(X_train_scaled, y_train, 
                   validation_data=(X_val_scaled, y_val),
                   epochs=100, 
                   batch_size=32, 
                   verbose=1)

print("\nEntrenamiento completado")





# Evaluar el modelo en el conjunto de prueba
y_pred = model.predict(X_test_scaled, verbose=0)

# Calcular m√©tricas
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred.flatten()) / y_test)) * 100

print("RENDIMIENTO DEL MODELO")
print("=" * 50)
print(f"Error Absoluto Medio (MAE):     {mae:.2f} MPa")
print(f"Error Cuadr√°tico Medio (MSE):   {mse:.2f}")
print(f"Ra√≠z del MSE (RMSE):           {rmse:.2f} MPa")
print(f"Coeficiente de Determinaci√≥n (R¬≤): {r2:.4f}")
print(f"Error Porcentual Absoluto Medio: {mape:.2f}%")





# Gr√°ficos de entrenamiento
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Gr√°fico 1: P√©rdida durante entrenamiento
axes[0, 0].plot(history.history['loss'], label='Entrenamiento')
axes[0, 0].plot(history.history['val_loss'], label='Validaci√≥n')
axes[0, 0].set_title('P√©rdida del Modelo')
axes[0, 0].set_xlabel('√âpoca')
axes[0, 0].set_ylabel('MSE')
axes[0, 0].legend()
axes[0, 0].grid(True)

# Gr√°fico 2: MAE durante entrenamiento
axes[0, 1].plot(history.history['mae'], label='Entrenamiento')
axes[0, 1].plot(history.history['val_mae'], label='Validaci√≥n')
axes[0, 1].set_title('Error Absoluto Medio')
axes[0, 1].set_xlabel('√âpoca')
axes[0, 1].set_ylabel('MAE')
axes[0, 1].legend()
axes[0, 1].grid(True)

# Gr√°fico 3: Predicho vs Real
axes[1, 0].scatter(y_test, y_pred, alpha=0.6)
axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axes[1, 0].set_xlabel('Resistencia Real (MPa)')
axes[1, 0].set_ylabel('Resistencia Predicha (MPa)')
axes[1, 0].set_title('Predicho vs Real')
axes[1, 0].grid(True)

# Gr√°fico 4: Distribuci√≥n de errores
errors = y_test - y_pred.flatten()
axes[1, 1].hist(errors, bins=30, alpha=0.7, edgecolor='black')
axes[1, 1].set_xlabel('Error (Real - Predicho)')
axes[1, 1].set_ylabel('Frecuencia')
axes[1, 1].set_title('Distribuci√≥n de Errores')
axes[1, 1].grid(True)

plt.tight_layout()
plt.show()





def generate_random_samples(feature_names, n_samples=5):
    """Genera muestras aleatorias basadas en rangos t√≠picos del dataset"""
    print(f"Generando {n_samples} muestras aleatorias para predicci√≥n...")
    
    random_samples = []
    
    # Rangos t√≠picos basados en el an√°lisis del dataset
    ranges = {
        'cement': (100, 540),
        'slag': (0, 360),
        'flyash': (0, 200),
        'water': (120, 220),
        'superplasticizer': (0, 35),
        'coarseaggregate': (800, 1150),
        'fineaggregate': (600, 950),
        'age': (1, 365)
    }
    
    for i in range(n_samples):
        sample = []
        print(f"\nMuestra {i+1}:")
        for feature in feature_names:
            if feature in ranges:
                min_val, max_val = ranges[feature]
                value = np.random.uniform(min_val, max_val)
            else:
                # Usar estad√≠sticas del dataset si no hay rango definido
                feature_data = data[feature]
                mean = feature_data.mean()
                std = feature_data.std()
                value = np.random.normal(mean, std)
                value = max(0, value)  # Asegurar valores no negativos
            
            sample.append(value)
            print(f"  {feature:20s}: {value:8.2f}")
        
        random_samples.append(sample)
    
    return np.array(random_samples)

# Generar muestras aleatorias
random_samples = generate_random_samples(feature_names, n_samples=5)





# Normalizar las muestras aleatorias
random_samples_scaled = scaler.transform(random_samples)

# Hacer predicciones
predictions = model.predict(random_samples_scaled, verbose=0)

print("\n" + "="*60)
print("RESULTADOS DE PREDICCI√ìN")
print("="*60)

results = []

for i, (sample, pred) in enumerate(zip(random_samples, predictions)):
    print(f"\nMUESTRA {i+1}:")
    print("-" * 40)
    
    # Mostrar valores de entrada
    print("Valores de entrada:")
    for j, (feature, value) in enumerate(zip(feature_names, sample)):
        print(f"  {feature:20s}: {value:8.2f}")
    
    # Mostrar predicci√≥n
    pred_value = pred[0]
    print(f"\nRESISTENCIA PREDICHA: {pred_value:.2f} MPa")
    
    # Clasificar la resistencia
    if pred_value < 20:
        classification = "Baja resistencia"
    elif pred_value < 40:
        classification = "Resistencia media"
    elif pred_value < 60:
        classification = "Alta resistencia"
    else:
        classification = "Muy alta resistencia"
    
    print(f"Clasificaci√≥n: {classification}")
    
    results.append({
        'sample_id': i+1,
        'inputs': dict(zip(feature_names, sample)),
        'predicted_strength': pred_value,
        'classification': classification
    })





# Crear DataFrame con los resultados
results_df = pd.DataFrame()

for i, result in enumerate(results):
    row_data = result['inputs'].copy()
    row_data['Resistencia_Predicha_MPa'] = result['predicted_strength']
    row_data['Clasificacion'] = result['classification']
    
    results_df = pd.concat([results_df, pd.DataFrame([row_data])], ignore_index=True)

# Mostrar tabla de resultados
print("TABLA RESUMEN DE PREDICCIONES")
print("=" * 80)
results_df.round(2)





# Gr√°fico de barras con las predicciones
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Gr√°fico 1: Resistencias predichas
sample_names = [f'Muestra {i+1}' for i in range(len(results))]
predicted_strengths = [result['predicted_strength'] for result in results]

bars = axes[0].bar(sample_names, predicted_strengths, color='skyblue', edgecolor='navy')
axes[0].set_title('Resistencias Predichas para Muestras Aleatorias')
axes[0].set_ylabel('Resistencia (MPa)')
axes[0].set_xlabel('Muestras')
axes[0].grid(True, alpha=0.3)

# A√±adir valores en las barras
for bar, strength in zip(bars, predicted_strengths):
    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                f'{strength:.1f}', ha='center', va='bottom', fontweight='bold')

# Gr√°fico 2: Comparaci√≥n con distribuci√≥n original
axes[1].hist(data['csMPa'], bins=30, alpha=0.7, label='Dataset Original', color='lightcoral')
axes[1].axvline(x=np.mean(predicted_strengths), color='blue', linestyle='--', 
               linewidth=2, label=f'Promedio Predicciones: {np.mean(predicted_strengths):.1f} MPa')
axes[1].set_xlabel('Resistencia (MPa)')
axes[1].set_ylabel('Frecuencia')
axes[1].set_title('Distribuci√≥n de Resistencias')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()





print("\n" + "="*60)
print("RESUMEN FINAL Y CONCLUSIONES")
print("="*60)

print(f"\nüìä RENDIMIENTO DEL MODELO:")
print(f"   ‚Ä¢ Modelo entrenado con {len(X_train)} muestras")
print(f"   ‚Ä¢ Evaluado en {len(X_test)} muestras de prueba")
print(f"   ‚Ä¢ Error promedio: {mae:.2f} MPa")
print(f"   ‚Ä¢ Precisi√≥n del modelo (R¬≤): {r2:.4f} ({r2*100:.1f}%)")
print(f"   ‚Ä¢ Error porcentual: {mape:.2f}%")

print(f"\nüî¨ PREDICCIONES REALIZADAS:")
for result in results:
    print(f"   ‚Ä¢ Muestra {result['sample_id']}: {result['predicted_strength']:.2f} MPa ({result['classification']})")

print(f"\nüìà ESTAD√çSTICAS DE PREDICCIONES:")
pred_mean = np.mean(predicted_strengths)
pred_std = np.std(predicted_strengths)
pred_min = np.min(predicted_strengths)
pred_max = np.max(predicted_strengths)

print(f"   ‚Ä¢ Resistencia promedio predicha: {pred_mean:.2f} MPa")
print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {pred_std:.2f} MPa")
print(f"   ‚Ä¢ Rango: {pred_min:.2f} - {pred_max:.2f} MPa")

print(f"\n‚úÖ CONCLUSIONES:")
print(f"   ‚Ä¢ El modelo muestra un buen rendimiento con R¬≤ = {r2:.4f}")
print(f"   ‚Ä¢ Error promedio de ¬±{mae:.2f} MPa es aceptable para aplicaciones pr√°cticas")
print(f"   ‚Ä¢ Las predicciones con valores aleatorios muestran resistencias realistas")
print(f"   ‚Ä¢ El modelo puede ser utilizado para estimar la resistencia del concreto")
print(f"     basado en su composici√≥n y edad")



